# v0.4 — Supabase + Langfuse Tracking

**Date:** 2026-02-27
**Analyst:** Cursor AI Agent (Claude)
**Source chats:**
- Session 1: Supabase + Langfuse architecture, extended thinking, structured reasoning, implementation
- Session 2: Architecture fix (parent trace), correlation key, UI polish, report sync, code audit, integration tests

---

## Goal

Set up comprehensive observability for both user behavior and AI agent reasoning:
- **Langfuse** — AI agent observability: traces every Claude call with extended thinking, token usage, cost, latency. Instrumented at the `agent.py` level so it survives any frontend change.
- **Supabase** — User/product data: sessions, analysis runs, user events (clicks, downloads), and full report persistence. Solves issue #20 (ephemeral cloud reports).

Design principle: the observability layer must be sustainable beyond Streamlit — when the product pivots to an independent web app or OpenClaw plugin, Langfuse stays as-is and only the Supabase user-event tracking needs frontend-specific updates.

---

## Changes Made During This Version

### Extended Thinking enabled (`agent.py`)
- **What:** `plan_searches()` and `analyze_compliance()` now use Claude's Extended Thinking feature. The `thinking` parameter is enabled with budget_tokens of 3,000 (planning) and 8,000 (analysis). `max_tokens` increased to 5,000 and 16,000 respectively.
- **Return type change:** Both functions now return dicts instead of plain strings/lists. Dicts include `thinking` (Claude's internal chain-of-thought), `tokens_in`, `tokens_out`, plus the original output (`queries` or `analysis`).
- **Why:** The user explicitly wants to log Claude's internal reasoning process — not just inputs/outputs but the actual thinking behind each decision.

### Langfuse instrumentation (`agent.py`)
- **What:** Added `@observe()` decorators on `plan_searches()`, `conduct_research()`, `analyze_compliance()`, and `run_analysis()`. Added `AnthropicInstrumentor().instrument()` for automatic Claude API call tracing.
- **What it captures:** Nested traces per pipeline run, Claude API calls with model/tokens/cost, extended thinking blocks, function inputs/outputs, timing.
- **Why:** Purpose-built LLM observability tool — gives a dashboard, cost tracking, and trace visualization out of the box. Frontend-agnostic (decorators are on agent.py).

### Structured reasoning prompts (`prompts.py`)
- **What:** Updated `SEARCH_PLANNING_PROMPT` to ask Claude for a "Reasoning" section explaining why it chose each query, what it expects to find, and what it excluded. Updated `ANALYSIS_PROMPT` to add an "Agent Reasoning" section at the end of every report explaining prioritization decisions, influential findings, research gaps, and assumptions.
- **Why:** Extended thinking captures raw chain-of-thought; structured reasoning captures guided, user-readable explanations. Both are logged.

### Supabase tracking module (`tracking.py`) — NEW FILE
- **What:** New module with fail-safe Supabase integration using `postgrest` (lightweight PostgREST client instead of the full `supabase` SDK which has heavy C dependencies).
- **Functions:** `init_session()`, `start_run()`, `complete_run()`, `log_user_event()`, `save_report_to_db()`
- **Fail-safe:** All functions wrapped with `@_safe` decorator — Supabase errors are printed but never crash the app. If Supabase credentials are missing, tracking is silently disabled.
- **Why:** Track user behavior (what they input, download, click) and persist reports (solves ephemeral cloud storage issue).

### Supabase schema (`supabase_schema.sql`) — NEW FILE
- **What:** SQL schema for 4 tables: `sessions`, `analysis_runs`, `user_events`, `reports`. Includes indexes for common queries.
- **No agent_steps table:** AI agent step tracking is handled entirely by Langfuse. Supabase only stores user/product data.
- **Why:** Reference file for setting up the database. Run in Supabase SQL Editor.

### Streamlit app updates (`streamlit_app.py`)
- **What:** Added Supabase user event tracking at each interaction point (page load, scenario selection, analysis start, report download). Added secrets injection for Supabase and Langfuse env vars. Updated pipeline calls to handle new dict return types from `plan_searches()` and `analyze_compliance()`.
- **Version bumped to v0.4.**

### Version bump (`agent.py`)
- **What:** Default `version` parameter in `run_analysis()` changed from `"v0.3"` to `"v0.4"`.

### Dependencies (`requirements.txt`)
- **Added:** `postgrest>=2.28.0`, `langfuse>=4.0.0b1`, `opentelemetry-instrumentation-anthropic>=0.35.0`
- **Note:** Used `postgrest` instead of `supabase` SDK because the full SDK pulls in `pyiceberg` which requires C++ build tools on Windows. `postgrest` provides all the database operations we need.

---

## Architecture

```
User (Streamlit) → streamlit_app.py → agent.py → Claude API
                        │                  │
                        │                  └──→ Langfuse (traces, thinking, tokens, cost)
                        │
                        └──→ Supabase (sessions, runs, events, reports)

Langfuse trace structure (after Session 2 fix):
  compliance_pipeline (parent trace — tagged with run_id + session_id)
    ├── plan_searches()      (child span)
    ├── conduct_research()   (child span)
    └── analyze_compliance() (child span)

Cross-service correlation key: run_id (Supabase analysis_runs.id)
  → embedded in: local report header, test-log.csv, Langfuse trace metadata
  → links to: Supabase analysis_runs, reports, user_events, sessions
```

**What lives where:**
- Langfuse: Claude API calls, extended thinking, token usage, cost, per-step timing, function I/O
- Supabase: User sessions, analysis run metadata, UI interaction events, full report content
- CSV (kept as local backup): Same performance data as before, append-only
- `run_id`: Universal correlation key — present in all three systems

### Langfuse Trace Architecture Fix (Session 2)

**Before (fragmented — the root cause):**
```
streamlit_app.py inline code:
    plan_searches()        → Langfuse Trace A (isolated)
    conduct_research()     → Langfuse Trace B (isolated)
    analyze_compliance()   → Langfuse Trace C (isolated)

    No grouping. No way to correlate. No run_id anywhere.
```

**After (unified):**
```
streamlit_app.py:
    _run_pipeline()        → Langfuse Parent Trace (tagged: run_id, session_id)
        ├── plan_searches()     → Child Span 1
        ├── conduct_research()  → Child Span 2
        └── analyze_compliance() → Child Span 3

    run_id embedded in: report header, test-log.csv, Langfuse metadata
```

**Cross-service navigation (any direction):**
- **Local report → Supabase:** look up the `run_id` in the report header
- **Supabase → Local report:** match by `report_filename` or `run_id` in test-log.csv
- **Local report → Langfuse:** search Langfuse traces by `supabase_run_id` in metadata
- **Langfuse → Supabase:** the trace metadata contains `supabase_run_id`

### Agent Behavior Rule (Session 2)

Combined into `.cursor/rules/agent-behavior.mdc` with three sections:
1. **No assumptions** — confirm before acting (existing, moved from `no-assumptions.mdc`)
2. **Surface architectural root causes** — stop and flag to user instead of patching symptoms (new)
3. **Product marketing thinking** — user-facing text should present the agent as the product, not the underlying model (new)

---

## Test Results

### Connection Test (`test_tracking.py`)
- **Supabase:** Initial insert failed due to Row Level Security (RLS enabled by default). Fixed by running `alter table ... disable row level security;` on all 4 tables. After fix: all inserts/reads passed — sessions, analysis_runs, user_events, reports all accessible.
- **Langfuse:** Client initialized, traced function executed, data flushed to dashboard. Pydantic V1 warning on Python 3.14 (cosmetic, non-blocking).
- **Result:** Both services connected and working.

### Streamlit Cloud Deployment
- **Secrets added:** SUPABASE_URL, SUPABASE_KEY, LANGFUSE_SECRET_KEY, LANGFUSE_PUBLIC_KEY, LANGFUSE_HOST added to Streamlit Cloud secrets dashboard.
- **Code pushed:** Commit `9899e0c` deployed via GitHub integration.
- **App tested:** Live demo at https://ai-compliance-gap-analyzer.streamlit.app/

### UptimeRobot Monitor
- **What:** Free uptime monitor pinging the Streamlit Cloud app every 5 minutes to prevent free-tier sleep behavior.
- **Why:** Streamlit Cloud free tier puts apps to sleep after inactivity. Users were seeing "app has gone to sleep" with a long wake-up time (reinstalling all dependencies on cold start).

### UI polish — step messages (`streamlit_app.py`) — Session 2
- **What:** Removed "Claude" name-drops from pipeline step progress messages. "asking Claude what to investigate" → "identifying key regulations to investigate". "Claude is writing the report" → "the agent is cross-referencing findings and writing your report."
- **Why:** Users seeing "Claude is doing X" undermines the product identity — makes it feel like a wrapper they could replicate in a chat session. The agent should present itself as the product, not as Claude.

### Timer expectation management (`streamlit_app.py`) — Session 2
- **What:** Updated elapsed timer subtitle from "This usually takes 2–3 minutes" to "Usually 2–3 min · may take longer for complex or region-specific cases".
- **Why:** Some analyses (particularly RegTech and documentation tool scenarios) took 3–5 minutes. The original estimate set false expectations and caused user frustration.

### Parent Langfuse trace — architecture fix (`streamlit_app.py`) — Session 2
- **What:** Extracted the three pipeline steps into a `@observe(name="compliance_pipeline")` decorated function `_run_pipeline()`. This creates a single parent Langfuse trace that groups all child spans (`plan_searches`, `conduct_research`, `analyze_compliance`) under one trace.
- **Root cause fixed:** Previously, `streamlit_app.py` called each pipeline function directly inline, creating three separate Langfuse traces with no parent grouping. This made it impossible to correlate all steps of a single analysis in Langfuse. The new architecture nests them naturally.
- **Trace metadata:** The parent trace is tagged with `run_id`, `session_id`, and `app_version` via OTel span attributes, enabling cross-service correlation between Langfuse and Supabase.
- **Why:** The user needed to match local documentation with Supabase and Langfuse records for analysis. The fragmented trace architecture was the root blocker.

### Universal correlation key (`run_id`) — Session 2
- **What:** The Supabase `run_id` (UUID from `analysis_runs.id`) is now embedded in:
  - Local report headers (`**Run ID:** \`...\``)
  - `test-log.csv` (new `run_id` column)
  - Langfuse parent trace metadata (`supabase_run_id`)
  - Synced reports from `sync_reports.py`
- **Files modified:** `agent.py` (`save_report()`, `append_test_log()`), `streamlit_app.py`, `sync_reports.py`
- **Why:** Provides a single key to navigate between any local report → Supabase records → Langfuse traces.

### Cursor rules consolidated — Session 2
- **What:** Combined `no-assumptions.mdc` into a new `agent-behavior.mdc` that consolidates all agent behavior rules: no assumptions, surface architectural root causes, and product marketing thinking for user-facing content.
- **Deleted:** `no-assumptions.mdc` (superseded by `agent-behavior.mdc`)
- **Why:** User requested combining all agent behavior rules into one file for coherence.

### Integration test suite (`test_tracking.py`) — Session 2
- **What:** Expanded from basic connection test to 4-part integration test:
  1. Supabase connection + cross-table linkage (session → run → report → events all linked by IDs)
  2. Langfuse connection + basic tracing
  3. Parent trace architecture (mock pipeline with nested `@observe()` spans, OTel metadata tagging)
  4. Local report correlation (`save_report()` embeds `run_id` in header, `append_test_log()` writes `run_id` to CSV)
- **Result:** All 4 tests passed.

### CSV column migration (`agent.py`, `sync_reports.py`) — Session 2
- **What:** Added automatic one-time migration for existing `test-log.csv` files that lack the `run_id` column. Both `agent.py` and `sync_reports.py` check the CSV header before appending — if `run_id` is missing, the file is rewritten with the new column (empty for old rows). Canonical field order defined in `_TEST_LOG_FIELDS` constant.
- **Why:** Code audit found that `streamlit_app.py` passed `run_id` to `save_report()` and `append_test_log()`, but the functions in `agent.py` hadn't been updated to accept it — would have crashed at runtime. Also fixed column alignment between `agent.py` and `sync_reports.py`.

### Report sync utility (`sync_reports.py`) — NEW FILE — Session 2
- **What:** CLI script that pulls cloud-generated reports from Supabase and saves them locally to `reports/` with proper naming. Also appends missing entries to `test-log.csv`. Idempotent — re-running skips already-synced reports.
- **Usage:** `python sync_reports.py` (sync all) or `python sync_reports.py --list` (preview without downloading).
- **Why:** Reports generated on Streamlit Cloud are saved to Supabase but not to the local git repo. This script closes the loop — ensures the local `reports/` folder and `test-log.csv` have a complete record of all analyses, regardless of where they ran.

---

## Remaining Issues for v0.5

### From v0.2/v0.3 (still deferred)
| # | Issue | Source |
|---|---|---|
| 9 | System prompt misleading about tool access | Code analysis |
| 7 | Pipeline → agent loop (add research adequacy check) | Code analysis |
| 5 | Retry logic for API calls | Code analysis |
| 8 | Multi-turn Claude context (stateless calls) | Code analysis |
| 13 | Pre-process research text before sending to Claude | Code analysis |
| 14 | Include raw research sources in saved report | Code analysis |
| 22 | API cost exposure — public demo has no rate limiting | Cloud deployment |

### New from v0.4
| # | Issue | Source |
|---|---|---|
| 23 | Langfuse Pydantic V1 warning on Python 3.14 — works but logs a warning | Dependency install |
| 24 | Supabase RLS disabled — fine for portfolio project, needs RLS if product goes live | Architecture decision |
| 25 | Extended thinking increases API cost — monitor token usage via Langfuse | Architecture decision |
| 26 | Streamlit Cloud deployment needs updated secrets (Supabase + Langfuse keys) | Resolved — secrets added to dashboard |
| 27 | Streamlit Cloud free tier sleep behavior — mitigated with UptimeRobot pinger | Deployment |

---

## Version Log
- **2026-02-27** — v0.4 started, version bumped in `agent.py` and `streamlit_app.py`
- **2026-02-27** — Created `supabase_schema.sql` with 4 tables
- **2026-02-27** — Enabled Extended Thinking on `plan_searches()` and `analyze_compliance()`
- **2026-02-27** — Added Langfuse `@observe()` decorators and `AnthropicInstrumentor`
- **2026-02-27** — Updated prompts.py with structured reasoning sections
- **2026-02-27** — Created `tracking.py` with fail-safe Supabase tracking functions
- **2026-02-27** — Instrumented `streamlit_app.py` with user event tracking
- **2026-02-27** — Added `postgrest`, `langfuse`, `opentelemetry-instrumentation-anthropic` to requirements
- **2026-02-27** — Resolved Langfuse Python 3.14 compatibility by upgrading to v4.0.0b1
- **2026-02-27** — No-assumptions rule added to `.cursor/rules/`
- **2026-02-27** — Created `test_tracking.py` for connection verification
- **2026-02-27** — Fixed Supabase RLS — disabled on all 4 tables for anon key access
- **2026-02-27** — Connection tests passed: Supabase all operations OK, Langfuse traces flushed
- **2026-02-27** — Streamlit Cloud secrets updated (5 new keys), code pushed and deployed
- **2026-02-27** — UptimeRobot monitor set up to prevent Streamlit Cloud free tier sleep
- **2026-02-28** — Session 2: Removed Claude name-drops from step messages (product identity)
- **2026-02-28** — Updated timer text with variable time expectation caveat
- **2026-02-28** — Created `sync_reports.py` for pulling cloud reports to local docs
- **2026-02-28** — Synced 3 cloud reports from Supabase to local `reports/`
- **2026-02-28** — Reviewed Supabase schema, provided join queries and session_overview view
- **2026-02-28** — Fixed UTC vs local timestamp inconsistency in sync_reports.py
- **2026-02-28** — Added `run_id` correlation key to report headers, test-log.csv, and Langfuse traces
- **2026-02-28** — Created `_run_pipeline()` with `@observe()` parent trace — fixed fragmented Langfuse trace architecture
- **2026-02-28** — Consolidated agent behavior rules into `.cursor/rules/agent-behavior.mdc`
- **2026-02-28** — Code audit: found and fixed 2 critical misalignments (save_report/append_test_log missing run_id params)
- **2026-02-28** — Added CSV column migration for test-log.csv (run_id column)
- **2026-02-28** — Expanded `test_tracking.py` to 4-part integration test (Supabase, Langfuse, parent trace, local correlation)
- **2026-02-28** — All 4 integration tests passed
- **2026-02-28** — Added known non-bug rule to documentation-system.mdc (Windows GBK emoji = Cursor bug)
- **2026-02-28** — Updated PROJECT-SCHEMA.md with branching strategy
- **2026-02-28** — Streamlit Cloud TypeError (save_report run_id) — root cause: module cache; fix: reboot app; gap: no structured error logging
