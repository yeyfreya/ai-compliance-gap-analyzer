# v0.5 — Error Handling, Error Logging & Rate Limiting

**Date:** 2026-02-28
**Analyst:** Cursor AI Agent (Claude)
**Source chats:**
- Session 1: Error tracing strategy, prioritized backlog, implementation
- Session 2: Pre-merge review, code cleanup, README accuracy fix, documentation guide improvement

---

## Goal

Prepare the app for public user testing (LinkedIn launch) by adding:
1. **Error handling** — catch all pipeline errors, show friendly UI, never expose raw tracebacks
2. **Error logging** — persist every error to Supabase with full context (session, run, step, traceback)
3. **Failed run tracking** — use existing `analysis_runs.status='error'` + `error_message` columns
4. **Invisible rate limiting** — per-session analysis limit to prevent API budget burn
5. **Retry logic** — 1-retry with backoff for transient Claude/Tavily errors

### Error Tracing Layers

The user identified three layers of errors, each requiring a different approach:

| Layer | What | Detection | v0.5 Approach |
|-------|------|-----------|---------------|
| **1. Code crashes** | Python exceptions — kills the user session | Try/except + Supabase error logging | Full coverage |
| **2. Bad output** | Pipeline completes but report quality is poor | Heuristics, user feedback | Deferred to v0.6 (basic heuristics only) |
| **3. Platform issues** | Streamlit Cloud cold starts, resource limits, deployment failures | UptimeRobot (already exists), platform logs | Already mitigated; errors that manifest as Python exceptions will be caught by Layer 1 |

### Architecture Decision: Error Logging Destination

**Chosen: Supabase** (over Sentry or Python logging)

Rationale:
- Already have Supabase infrastructure with session/run correlation
- Errors naturally link to `session_id` and `run_id` — can see exactly what user was doing
- No new service to manage (already have Supabase + Langfuse + UptimeRobot)
- Queryable via SQL alongside existing user/run data

### Rate Limiting Decision

**Chosen: Invisible per-session limit** (over access code gate)

Rationale:
- Zero friction for users — critical for LinkedIn launch conversion
- User experiences the core value immediately
- Limit message doubles as lead-gen: "Reach out to me for more access"
- Implementation: count `analysis_runs` by `session_id` before starting new run

---

## Combined Issue Backlog — Prioritized for Pre-LinkedIn Launch

### CRITICAL — Must fix before launch

| # | Issue | Why Critical | v0.5? |
|---|-------|-------------|-------|
| NEW | No try/except in `streamlit_app.py` around pipeline | Users see raw Python tracebacks on any error | Yes |
| 28 | No structured error logging | Can't know when users hit errors | Yes |
| 22 | No rate limiting on public demo | Someone could burn through entire API budget | Yes (invisible) |

### HIGH — Should fix before launch

| # | Issue | Why High | v0.5? |
|---|-------|---------|-------|
| 5 | No retry logic for API calls | A single Claude/Tavily timeout kills the session | Yes |
| NEW | `conduct_research()` silently swallows search failures | If 3/5 Tavily searches fail, Claude gets almost no data but still writes a report | Partial — error logging will capture it |
| NEW | `save_report()` / `append_test_log()` can crash on Streamlit Cloud | File I/O on ephemeral filesystem; report generated but crashes before user sees it | Yes — wrapped in error handling |

### MEDIUM — Can launch without, fix in next iteration

| # | Issue | Notes |
|---|-------|-------|
| 7 | Pipeline → agent loop (research adequacy check) | Would catch "bad research = bad report" but bigger architectural change |
| 9 | System prompt misleading about tool access | Affects analysis accuracy, not crashes |
| 13 | Pre-process research text before sending to Claude | Optimization — reduces tokens/cost |
| NEW | Report quality heuristics (basic checks) | Lightweight Layer 2 protection |
| NEW | User feedback button (thumbs up/down) | Manual Layer 2 signal |

### LOW — Post-launch improvements

| # | Issue | Notes |
|---|-------|-------|
| 8 | Multi-turn Claude context (stateless calls) | Nice-to-have for quality |
| 14 | Include raw research sources in saved report | Nice-to-have for transparency |
| 23 | Langfuse Pydantic V1 warning | Cosmetic, works fine |
| 24 | Supabase RLS disabled | Only matters if user auth is added |
| 25 | Extended thinking cost monitoring | Monitor via Langfuse, not urgent |

---

## Changes Made During This Version

### Retry logic (`agent.py`, `tools.py`)
- **What:** Added `_retry_api_call()` helper in `agent.py` — retries once with exponential backoff on transient errors (rate limits, server overloaded, timeouts, connection errors). Does NOT retry on auth errors or invalid requests.
- **Where used:** Both `plan_searches()` and `analyze_compliance()` Claude API calls now wrapped in `_retry_api_call()`.
- **Tavily:** `search_web()` in `tools.py` now retries once (2s backoff) on any search failure before returning error.
- **Why:** A single API timeout previously killed the user's entire session. Transient errors are common with external APIs.

### Error key in fallback returns (`agent.py`)
- **What:** When `plan_searches()` or `analyze_compliance()` falls back due to API errors, the return dict now includes an `"error"` key with the error description.
- **Why:** Enables downstream code to detect degraded results vs successful ones.

### Error logging to Supabase (`tracking.py`, `supabase_schema.sql`)
- **What:** New `error_logs` table in Supabase with columns: `error_type`, `error_message`, `error_traceback`, `pipeline_step`, `user_inputs` (jsonb), `session_id`, `run_id`, `app_version`. New `log_error()` function in `tracking.py`.
- **Fail-safe:** Uses same `@_safe` decorator — if Supabase is down, error logging fails silently (the user still sees the friendly error message).
- **Why:** Previously errors only surfaced in Streamlit UI or `print()` statements — no persistent record for debugging.

### Failed run marking (`tracking.py`)
- **What:** New `mark_run_failed()` function updates `analysis_runs.status='error'` and sets `error_message`. The `status` and `error_message` columns already existed in the schema from v0.4 but were never used.
- **Why:** Can now query Supabase to find all failed runs and their errors.

### Error handling in Streamlit app (`streamlit_app.py`)
- **What:** Full try/except around `_run_pipeline()` call. On pipeline failure: logs error to Supabase (`log_error`), marks run as failed (`mark_run_failed`), shows friendly error message with run_id reference, logs `pipeline_error` user event. Separate try/except around `save_report()` / `append_test_log()` — if save fails, user still sees the report via in-memory fallback.
- **Why:** Previously any unhandled exception showed raw Python tracebacks to users.

### Download button resilience (`streamlit_app.py`)
- **What:** Download button handles `report_path=None` case (when local save fails). Falls back to `"compliance_report.md"` filename and shows warning caption.
- **Why:** Edge case on Streamlit Cloud ephemeral filesystem.

### Invisible rate limiting (`tracking.py`, `streamlit_app.py`)
- **What:** `MAX_RUNS_PER_SESSION = 3`. Before each analysis, `is_rate_limited()` counts `analysis_runs` by `session_id`. If limit reached, shows a friendly message with LinkedIn link for feedback. Defaults to allowing if Supabase is unavailable.
- **Event logged:** `rate_limited` event in `user_events` when a user hits the limit.
- **Why:** Protects API budget for public demo without adding onboarding friction. The limit message doubles as lead generation.

### Supabase schema update (`supabase_schema.sql`)
- **What:** Added `error_logs` table (5th table), disabled RLS on it, added indexes on `session_id` and `created_at`.
- **Action required:** Run the new table SQL in Supabase SQL Editor before deploying.

### Concise report format (`prompts.py`, `agent.py`)
- **What:** Rewrote `ANALYSIS_PROMPT` for scannable, concise reports aimed at busy founders. New structure: Compliance Gap Matrix (5–8 rows max) → Key Regulatory Landscape (3–5 bullets) → Gap Details (grouped by risk level) → Recommended Next Steps (grouped by urgency) → Bottom Line (2–3 sentences). Removed "Agent Reasoning" section from report output (already captured in Extended Thinking + Langfuse). Reduced `max_tokens` from 16000→8000 and thinking budget from 8000→4000 to cut generation time.
- **Why:** Reports were 300–800 lines and took 2–5 minutes. For LinkedIn launch, the report needs to deliver value fast — if the builder can't stand waiting, no user will. Target: 150–250 lines, under 2 minutes.

### `load_dotenv()` in Streamlit app (`streamlit_app.py`)
- **What:** Added `load_dotenv()` before API key checks. Previously `.env` was only loaded when `agent.py` was imported, but the key check runs before the import.
- **Why:** Local runs showed "Missing API keys" error because env vars weren't loaded yet.

### Version bump
- **What:** `agent.py` and `streamlit_app.py` updated from `v0.4` to `v0.5`.

---

## Architecture

```
User (Streamlit) → streamlit_app.py → agent.py → Claude API
                        │                  │
                        │                  └──→ Langfuse (traces, thinking, tokens, cost)
                        │
                        └──→ Supabase
                              ├── sessions, analysis_runs, user_events, reports (v0.4)
                              └── error_logs (v0.5 — NEW)

Error flow:
  _run_pipeline() throws
    → catch in streamlit_app.py
    → log_error() → Supabase error_logs (type, message, traceback, step, inputs)
    → mark_run_failed() → Supabase analysis_runs (status='error', error_message)
    → st.error() → friendly message to user with run_id reference
    → log_user_event('pipeline_error') → Supabase user_events

Rate limit flow:
  Run Analysis clicked
    → is_rate_limited(session_id) → count analysis_runs for session
    → if used >= 3: show friendly limit message, log 'rate_limited' event, stop
    → else: proceed with pipeline

Retry flow (per API call):
  _retry_api_call(fn)
    → attempt 1: call fn()
    → if transient error (rate limit, timeout, 500, connection): wait 2s → attempt 2
    → if still fails: raise → caught by outer error handling
```

---

## Test Results

### Integration test (`test_tracking.py`) — 6/6 passed
1. Supabase connection + cross-table linkage — PASS
2. Langfuse connection + basic trace — PASS
3. Parent trace architecture (nested spans + metadata) — PASS
4. Local report correlation (run_id in report + CSV) — PASS
5. Error logging to Supabase (error_logs + mark_run_failed) — PASS
6. Rate limiting (per-session count) — PASS

### Streamlit app testing (local)
- **Happy path:** Reports generate successfully (~85–106s). Concise format (87–100 lines). Tone and content quality validated for initial launch.
- **Rate limiting:** 4th analysis in same session correctly blocked with friendly message and LinkedIn link.
- **Supabase:** `analysis_runs` correctly populated with `status='completed'`. `error_logs` empty (no errors — expected). `user_events` shows `rate_limited` event.
- **Report naming:** New format `report_v0.5_20260228_2229_slug.md` works, scannable in file explorer.
- **Timer:** "Usually about a minute" — accurate for new concise format.
- **Minor issue:** Report markdown formatting (heading levels, sub-grouping styles) varies slightly between runs. Formatting rules added to prompt but LLM doesn't follow them 100% consistently. Logged as issue #32 (LOW).

### MILESTONE
Report quality, tone, structure, and generation speed validated for LinkedIn launch.

---

## Remaining Issues for v0.6+

| Priority | # | Issue | Source | First Identified |
|----------|---|-------|--------|-----------------|
| **HIGH** | 29 | `conduct_research()` silently swallows individual search failures — Claude gets near-empty data but still writes a report | Code analysis | v0.5 |
| **HIGH** | 9 | System prompt misleading about tool access — tells Claude it has tools it doesn't | Code analysis | v0.1 |
| **HIGH** | 7 | Pipeline → agent loop (research adequacy check before analysis) | Code analysis | v0.2 |
| **MEDIUM** | 30 | Report quality heuristics — basic checks on output (length, required sections) | Layer 2 error detection | v0.5 |
| **MEDIUM** | 31 | User feedback button (thumbs up/down on reports) | Layer 2 manual signal | v0.5 |
| **MEDIUM** | 13 | Pre-process research text before sending to Claude (reduce tokens/cost) | Code analysis | v0.2 |
| **MEDIUM** | 14 | Include raw research sources in saved report | Code analysis | v0.2 |
| **LOW** | 8 | Multi-turn Claude context (stateless calls) | Code analysis | v0.1 |
| **LOW** | 23 | Langfuse Pydantic V1 warning on Python 3.14 — cosmetic, works fine | Dependency install | v0.4 |
| **LOW** | 24 | Supabase RLS disabled — needs RLS if product goes live with user accounts | Architecture decision | v0.4 |
| **LOW** | 25 | Extended thinking increases API cost — monitor via Langfuse | Architecture decision | v0.4 |
| **LOW** | 32 | Minor report format inconsistency — heading levels and sub-grouping styles vary slightly between runs despite explicit formatting instructions in prompt | Test runs | v0.5 |

---

## Version Log

- **2026-02-28** — v0.5 started, prioritized issue backlog created
- **2026-02-28** — Added `_retry_api_call()` to `agent.py`, retry in `tools.py`
- **2026-02-28** — Added `error_logs` table to `supabase_schema.sql`
- **2026-02-28** — Added `log_error()`, `mark_run_failed()`, `is_rate_limited()` to `tracking.py`
- **2026-02-28** — Full error handling + rate limiting wired into `streamlit_app.py`
- **2026-02-28** — Version bumped to v0.5 in `agent.py` and `streamlit_app.py`
- **2026-02-28** — Fixed `load_dotenv()` missing in `streamlit_app.py` (local run broke on key check)
- **2026-02-28** — Rewrote `ANALYSIS_PROMPT` for concise, scannable reports (150–250 lines target)
- **2026-02-28** — Reduced analysis `max_tokens` 16000→8000, thinking budget 8000→4000
- **2026-02-28** — Integration test: 6/6 passed. Streamlit test: rate limiting works, reports generate
- **2026-02-28** — Rewrote report voice/tone: gentle advisor, no assumptions about user's product, "potential gaps" language
- **2026-02-28** — Timer hint updated "2–3 min" → "Usually about a minute"; removed local file path from UI
- **2026-02-28** — Report filename format changed: date moved before slug, slug capped at 30 chars for scannability
- **2026-02-28** — **MILESTONE:** Report quality, tone, and structure validated for initial LinkedIn launch
- **2026-03-01** — Pre-merge review (Session 2): fixed `save_report()` default version `"v0.1"`→`"v0.5"`, removed unused `datetime` import from `streamlit_app.py`, sanitized local file paths in `.cursor/rules/pre-commit-review.mdc` and `docs/dev-logs/v0.1_...`, fixed stale README content (matrix name, timing, format description), added "product behavior changed" trigger to documentation guide and `documentation-system.mdc`
