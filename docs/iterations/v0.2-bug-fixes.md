# v0.2 — Bug Fixes & Hardening

**Date:** 2026-02-26
**Analyst:** Cursor AI Agent (Claude)
**Source chats:** *(to be filled at end of session)*

---

## Goal

Fix all remaining issues from v0.1 baseline analysis, ordered by priority:
1. **Fix Now** — Live bugs affecting correctness
2. **High** — Missing error handling and validation
3. **Medium** — Prompt improvements, architecture, dependency hygiene
4. **Low** — Quality-of-life improvements

Full issue list: [docs/iterations/v0.1-baseline.md](v0.1-baseline.md) → "Remaining Issues for v0.2"

---

## Changes Made During This Version

### Bug #1 — `format_search_results()` type mismatch [Fix Now]
- **File:** `tools.py` lines 76-89
- **Root cause:** `conduct_research()` in `agent.py` extracts the inner list from Tavily's response with `.get('results', [])` and passes that **list** to `format_search_results()`. But the function treated its input as a **dict** — checking for a `'results'` key and indexing with `search_results['results']`. Since lists don't have string keys, the guard clause always triggered, returning "No search results found" even when Tavily returned valid data.
- **Confirmed by:** v0.1 test run — Claude's output noted "search queries didn't return results" despite Tavily working.
- **Fix:** Changed `format_search_results()` to work with the list it actually receives. Removed the dict-style `'results' not in search_results` guard. Now iterates the list directly with `enumerate(search_results, 1)`. The type hint already declared `list`, so the implementation now matches its own contract.
- **Why this approach:** Fix the receiver, not the caller. The caller correctly extracts a clean list — changing it to pass the full dict would leak transport format into the formatter (worse separation of concerns).

### Bug #2 — Inconsistent indentation in `run_analysis()` [Fix Now]
- **File:** `agent.py` lines 199-206
- **Original finding:** Step comments had 5-space indentation instead of 4-space.
- **Status:** Already fixed. Current code has consistent 4-space indentation. Likely corrected during a previous edit session (file shows as modified/staged in git).
- **Action:** No code change needed — closed as already resolved.

### Bug #15 — `max_tokens=3000` too low [Fix Now]
- **File:** `agent.py` line 123
- **Root cause:** `analyze_compliance()` called Claude with `max_tokens=3000`. The v0.1 test run produced a ~280-line analysis with 10 gaps, 15 recommendations, and a risk matrix — but 3000 tokens wasn't enough. The report's Risk Prioritization Matrix was cut off mid-table.
- **Confirmed by:** v0.1 test run — report truncated at the end.
- **Fix:** Increased `max_tokens` from `3000` to `8000`. This is a ceiling, not a minimum — Claude still stops when its response is naturally complete. 8000 is generous enough for detailed analyses while staying well under Claude's context limit.
- **Why this approach:** Single-value change with minimal risk. The `plan_searches()` call keeps `max_tokens=1000` (search query lists are short). Only the analysis call needed the bump since that's the one producing long-form output.

### Bug #3 — No error handling on Claude API calls [High]
- **File:** `agent.py` — `plan_searches()` (lines 39-46) and `analyze_compliance()` (lines 121-128)
- **Root cause:** Both Claude API calls had zero error handling. If the API fails (rate limit, network timeout, invalid key, Anthropic outage), the entire pipeline crashes with a raw traceback. For `analyze_compliance()`, this also wastes all Tavily API credits already spent on research.
- **Fix:** Wrapped both API calls in `try/except anthropic.APIError`. `plan_searches()` falls through to its existing fallback queries so the pipeline continues. `analyze_compliance()` returns a clear error string that gets saved into the report, preserving research data for retry.
- **Why this approach:** Catches `anthropic.APIError` (SDK base class) rather than bare `Exception` — covers rate limits, auth, timeouts, server errors without swallowing unrelated exceptions. Errors handled in the core layer so any frontend (Streamlit, Flask, OpenClaw plugin) gets predictable behavior from `run_analysis()`.

### Bug #4 — No input validation on `run_analysis()` parameters [High]
- **File:** `agent.py` — `run_analysis()` entry point
- **Root cause:** Empty strings, whitespace-only, or extremely long inputs passed straight through to Claude and Tavily unchecked — burning API credits for nothing and producing reports with blank metadata.
- **Fix:** Added validation at the top of `run_analysis()` that checks all three inputs (`use_case`, `technology`, `industry`). Returns `{"error": "..."}` dict immediately if a field is empty/whitespace or exceeds 500 chars. No API calls made on invalid input.
- **Why this approach:** Returns an error dict (same shape check as normal result) rather than raising an exception — any frontend can check `if "error" in result:` and display accordingly. Validated in the core so it works regardless of frontend. 500-char limit prevents accidental token burning from copy-paste mistakes.

### Bug #6 — Bare `except` in `plan_searches()` [High]
- **File:** `agent.py` — `plan_searches()` JSON parsing fallback
- **Original finding:** Bare `except` clause silently swallowing all exceptions including `KeyboardInterrupt` and `MemoryError`.
- **Status:** Already fixed. Current code catches `(json.JSONDecodeError, ValueError, IndexError)` specifically. Corrected in a prior session (file was modified/staged in git).
- **Action:** No code change needed — closed as already resolved.

---

## Test Results

*(To be filled after running tests)*

---

## Remaining Issues for v0.3 (Deferred to Post-Launch)

Decision: Medium and Low priority bugs deferred to focus on Streamlit demo launch. The core pipeline is now correct and hardened — remaining items are quality/polish improvements.

### Medium Priority
| # | Issue | Source |
|---|---|---|
| 9 | System prompt misleading about tool access | Code analysis |
| 10 | Analysis prompt could request severity ratings, compliance scores | Code analysis |
| 7 | Pipeline → agent loop (add research adequacy check) | Code analysis |
| 11 | `requirements.txt` has no version pins | Code analysis |

### Low Priority
| # | Issue | Source |
|---|---|---|
| 5 | Retry logic for API calls | Code analysis |
| 8 | Multi-turn Claude context (stateless calls) | Code analysis |
| 12 | Remove unused `streamlit` from requirements (moot once Streamlit app is built) | Code analysis |
| 13 | Pre-process research text before sending to Claude | Code analysis |
| 14 | Include raw research sources in saved report | Code analysis |

---

## Version Log
- **2026-02-26** — v0.2 started, iteration doc created
- **2026-02-26** — Bug #1 fixed: `format_search_results()` type mismatch in `tools.py`
- **2026-02-26** — Bug #2 closed: indentation already fixed in prior session
- **2026-02-26** — Bug #15 fixed: `max_tokens` increased from 3000 to 8000 in `agent.py`
- **2026-02-26** — Bug #3 fixed: error handling added to both Claude API calls in `agent.py`
- **2026-02-26** — Bug #4 fixed: input validation added to `run_analysis()` in `agent.py`
- **2026-02-26** — Bug #6 closed: bare except already fixed in prior session
