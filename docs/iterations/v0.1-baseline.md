# v0.1 — Baseline Analysis

**Date:** 2026-02-25
**Analyst:** Cursor AI Agent (Claude)
**Source chats:** [Improve & Debug](69b8e4b8-b410-4ec4-9577-adc647ede4cd), [Git Setup & Docs](06161cb2-7704-4d8e-9142-e8b460b7c380)

---

## Project Snapshot

### Files
| File | Purpose | Lines |
|---|---|---|
| `agent.py` | Main orchestrator — plans, researches, analyzes, saves | 232 |
| `tools.py` | Tavily web search + result formatting | 93 |
| `prompts.py` | System prompt, search planning prompt, analysis prompt | 62 |
| `test_all.py` | Combined import + API integration test | 29 |
| `test_api.py` | Claude API connection test | 16 |
| `test_tavily.py` | Tavily search test | 12 |
| `requirements.txt` | Dependencies: anthropic, tavily-python, streamlit, python-dotenv | 4 |

### Architecture Flow
```
User Input (use_case, technology, industry)
    │
    ▼
plan_searches() ──► Claude generates 3-5 search queries
    │
    ▼
conduct_research() ──► Tavily executes each query (max 3 results each)
    │
    ▼
analyze_compliance() ──► Claude analyzes all findings
    │
    ▼
save_report() ──► Markdown file saved to reports/
```

### Changes Made During This Version
- `save_report()` was added during the "Improve & Debug" chat session.
  It writes timestamped markdown reports to a `reports/` subfolder with
  the use case slugified into the filename.

---

## Full Analysis Findings

### Strengths
1. **Clean separation of concerns** — tools, prompts, and agent logic are in separate files
2. **Good workflow design** — the 5-step pipeline (Input, Plan, Research, Analyze, Report) mirrors how a human analyst would approach this
3. **Resilient search planning** — `plan_searches()` has a sensible fallback if Claude's JSON parsing fails
4. **Error handling in `search_web()`** — try/except with structured error return is a good pattern
5. **Report persistence** — timestamped, use-case-named files give a clean audit trail

---

### Bugs

#### 1. `format_search_results()` type mismatch — LIVE BUG
- **Location:** `tools.py` line 77 vs `agent.py` line 89-93
- **Problem:** In `conduct_research()`, the code does `results = search_response.get('results', [])` which extracts the **inner list**, then passes it to `format_search_results(results)`. But `format_search_results()` treats its input as a **dict** — checking `'results' not in search_results` and iterating `search_results['results']`. The function receives a list but tries dict operations on it.
- **Impact:** Medium-High — the guard clause will always return "No search results found" even when searches succeed, meaning Claude may get empty research data.

#### 2. Inconsistent indentation in `run_analysis()`
- **Location:** `agent.py` lines 196, 199, 202
- **Problem:** Step comments have an extra leading space (5 spaces instead of 4)
- **Impact:** Cosmetic — doesn't break execution but inconsistent with rest of file

---

### Missing: Error Handling & Robustness

#### 3. No error handling on Claude API calls
- **Location:** `agent.py` lines 39-46 (`plan_searches`) and lines 121-128 (`analyze_compliance`)
- **Problem:** If Claude API fails (rate limit, network error, invalid response), the entire pipeline crashes with an unhandled exception
- **Impact:** High — no graceful degradation
- **Priority:** High

#### 4. No input validation
- **Location:** `agent.py` `run_analysis()` entry point
- **Problem:** Empty strings or extremely long inputs pass through unchecked, burning tokens for nothing
- **Priority:** High

#### 5. No retry logic for API calls
- **Problem:** Both Claude and Tavily calls can fail transiently. Even a simple 1-retry with backoff would improve reliability
- **Priority:** Low-Medium

#### 6. Bare `except` in `plan_searches()` (line 61)
- **Problem:** Silently swallows ALL exceptions including `KeyboardInterrupt` and `MemoryError`. Should catch `(json.JSONDecodeError, ValueError, IndexError)` specifically
- **Priority:** Medium

---

### Architecture Observations

#### 7. This is a pipeline, not yet an agent
- **Observation:** The workflow is strictly linear: plan → search → analyze → done. A true agent would have decision loops — e.g., "Are the research results sufficient? If not, plan and search again."
- **Recommendation:** Add a validation step where Claude evaluates whether research is adequate before moving to analysis
- **Priority:** Medium

#### 8. Each Claude call is stateless
- **Problem:** Both `plan_searches` and `analyze_compliance` start fresh conversations. The analysis step doesn't benefit from the planning step's reasoning.
- **Recommendation:** Pass conversation history forward or combine into a multi-turn flow so Claude has fuller context
- **Priority:** Low

---

### Prompt Quality Issues

#### 9. System prompt is misleading about tool access
- **Location:** `prompts.py` line 19
- **Problem:** Says "You have access to web search tools" but Claude doesn't actually have tool-use enabled — the code calls Tavily manually. Claude might hallucinate tool calls or reference capabilities it doesn't have.
- **Fix:** Change to "Research findings from web searches will be provided to you."
- **Priority:** Medium

#### 10. Analysis prompt could produce richer output
- **Problem:** Currently asks for 4 generic sections. Could get much more actionable output by requesting:
  - Severity/risk ratings (Critical / High / Medium / Low) per gap
  - Overall compliance score
  - Specific regulation article/section references
  - Prioritized action timeline
- **Priority:** Medium

---

### Code Quality & Dependencies

#### 11. `requirements.txt` has no version pins
- **Problem:** `anthropic`, `tavily-python`, etc. have no version constraints. A dependency update could break the project at any time.
- **Fix:** Pin to at least major versions (e.g., `anthropic>=0.40,<1.0`)
- **Priority:** Medium

#### 12. `streamlit` in requirements but unused
- **Problem:** Listed as a dependency but no Streamlit code exists yet. Adds unnecessary install weight.
- **Fix:** Remove until UI work begins, or keep if UI is planned for next version
- **Priority:** Low

---

### Report & Output Quality

#### 13. Raw research text dumped into analysis prompt
- **Problem:** The `research_findings` string is just concatenated search snippets. Pre-processing (deduplicating, summarizing, structuring) before passing to Claude would yield better analysis and use fewer tokens.
- **Priority:** Low

#### 14. Saved report doesn't include raw research findings
- **Problem:** If you ever need to audit *why* Claude reached a conclusion, the source material isn't in the report.
- **Fix:** Add an optional "Appendix: Research Sources" section to the saved markdown
- **Priority:** Low

---

## Priority Summary Table

| # | Issue | Category | Priority |
|---|---|---|---|
| 1 | `format_search_results` type bug | Bug | Fix Now |
| 2 | Indentation inconsistency | Bug | Fix Now |
| 3 | No error handling in orchestrator | Missing | High |
| 4 | No input validation | Missing | High |
| 6 | Bare `except` clause | Code smell | Medium |
| 9 | System prompt misleading | Prompt | Medium |
| 10 | Richer analysis prompt | Prompt | Medium |
| 7 | Pipeline → agent loop | Architecture | Medium |
| 11 | Pin dependency versions | Maintenance | Medium |
| 5 | Retry logic for API calls | Reliability | Low-Medium |
| 8 | Multi-turn Claude context | Architecture | Low |
| 12 | Remove unused streamlit | Cleanup | Low |
| 13 | Pre-process research text | Quality | Low |
| 14 | Include sources in report | Quality | Low |

---

## Test Results

**Test run:** 2026-02-25 15:59:51
**Use case:** AI-powered resume screening tool / OpenAI GPT-4 API / Enterprise HR tech (US-based)
**Report file:** `reports/report_v0.1_ai-powered-resume-screening-tool_20260225_155951.md`

### What Worked
- `plan_searches()` — Claude generated 5 well-targeted search queries (EEOC guidelines, OpenAI data policies, NYC LL144, adverse impact testing, OpenAI BAA/HIPAA)
- `search_web()` — Tavily executed searches successfully (no errors thrown)
- `analyze_compliance()` — Claude produced a thorough 280-line analysis covering 10 compliance gaps, 15 recommendations, and a risk prioritization matrix
- `save_report()` — report persisted correctly to `reports/` with timestamped filename
- Claude compensated for missing research data by using its own training knowledge — output was still highly useful

### What Failed / Issues Observed
- **format_search_results bug confirmed** — despite Tavily returning results, the type mismatch (list vs dict) caused all research data to be dropped. Claude's executive summary noted "search queries didn't return results" — confirming the bug is live and affecting output quality
- **max_tokens truncation** — the Risk Prioritization Matrix at the end of the report was cut off mid-table. `max_tokens=3000` in `analyze_compliance()` is too low for the level of detail Claude produces
- **Unicode encoding** — emoji characters in print statements caused `UnicodeEncodeError` in Cursor's terminal (GBK codec). Not a code bug — runs fine in the user's own terminal. Windows-specific encoding quirk

---

## Remaining Issues for v0.2

### Fix Now (Bugs)
| # | Issue | Source |
|---|---|---|
| 1 | `format_search_results` type mismatch — list vs dict | Code analysis + confirmed by test |
| 2 | Inconsistent indentation in `run_analysis()` (5-space vs 4-space) | Code analysis |
| 15 | `max_tokens=3000` too low — truncates analysis output | Test run |

### High Priority (Missing Features)
| # | Issue | Source |
|---|---|---|
| 3 | No error handling on Claude API calls | Code analysis |
| 4 | No input validation on `run_analysis()` parameters | Code analysis |
| 6 | Bare `except` in `plan_searches()` — should catch specific exceptions | Code analysis |

### Medium Priority (Improvements)
| # | Issue | Source |
|---|---|---|
| 9 | System prompt misleading about tool access | Code analysis |
| 10 | Analysis prompt could request severity ratings, compliance scores | Code analysis |
| 7 | Pipeline → agent loop (add research adequacy check) | Code analysis |
| 11 | `requirements.txt` has no version pins | Code analysis |

### Low Priority (Future)
| # | Issue | Source |
|---|---|---|
| 5 | Retry logic for API calls | Code analysis |
| 8 | Multi-turn Claude context (stateless calls) | Code analysis |
| 12 | Remove unused `streamlit` from requirements | Code analysis |
| 13 | Pre-process research text before sending to Claude | Code analysis |
| 14 | Include raw research sources in saved report | Code analysis |

---

## Version Log
- **2026-02-25** — `save_report()` added to `agent.py` (from "Improve & Debug" chat)
- **2026-02-25** — Version tagging added to `save_report()` and `run_analysis()`
- **2026-02-25** — Test run completed, report saved, baseline document finalized
- **2026-02-25** — v0.1 committed and pushed to GitHub
